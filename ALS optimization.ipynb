{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ./indexer\n",
    "from indexer import AppendIndexer\n",
    "import ALS\n",
    "\n",
    "# Annoy\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "#SKLearn \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse import lil_matrix\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewMatrix:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.original = True\n",
    "        self.item_indexer = AppendIndexer.load('./chetor.com/view_matrix/item_indexer.indexer')\n",
    "        self.user_indexer = AppendIndexer.load('./chetor.com/view_matrix/user_indexer.indexer')\n",
    "        \n",
    "    def load_matrix(path):\n",
    "        \n",
    "        matrix = ViewMatrix(path)\n",
    "\n",
    "        try:\n",
    "            matrix.view_matrix = ViewMatrix \\\n",
    "                .load_sparse_lil(path)\n",
    "        except:\n",
    "            print('Error: loading', path)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def load_sparse_lil(filename):\n",
    "        loader = np.load(filename, allow_pickle=True)\n",
    "        result = lil_matrix(tuple(loader[\"shape\"]), dtype=str(loader[\"dtype\"]))\n",
    "        result.data = loader[\"data\"]\n",
    "        result.rows = loader[\"rows\"]\n",
    "        return result\n",
    "    \n",
    "    def make_dense(self, user_min_view, item_min_view):\n",
    "        self.original = False\n",
    "        while True:\n",
    "            removed_rows_cnt = self.trim_users_with_few_views(user_min_view)\n",
    "            removed_columns_cnt = self.trim_columns_with_few_views(item_min_view)\n",
    "            if not removed_columns_cnt and not removed_rows_cnt:\n",
    "                break\n",
    "\n",
    "    def trim_users_with_few_views(self, user_min_view):\n",
    "        removing_row_indices = list(np.where(self.view_matrix.getnnz(1) < user_min_view)[0])\n",
    "        print('Number of users which should be deleted:', len(removing_row_indices))\n",
    "        self.trim_user_indices(to_remove_indices=removing_row_indices)\n",
    "        return len(removing_row_indices)\n",
    "\n",
    "    def trim_columns_with_few_views(self, column_min_view):\n",
    "        removing_column_indices = list(np.where(self.view_matrix.getnnz(0) < column_min_view)[0])\n",
    "        print('Number products which should be deleted:', len(removing_column_indices))\n",
    "        self.trim_column_indices(to_remove_indices=removing_column_indices)\n",
    "        return len(removing_column_indices)\n",
    "    \n",
    "    def trim_user_indices(self, to_remove_indices):\n",
    "        self.user_indexer.remove_indexes(to_remove_indices)\n",
    "        self.view_matrix = ViewMatrix.delete_row_lil(self.view_matrix, to_remove_indices)\n",
    "    \n",
    "    def trim_column_indices(self, to_remove_indices):\n",
    "        self.item_indexer.remove_indexes(to_remove_indices)\n",
    "        self.view_matrix = ViewMatrix.delete_column_lil(self.view_matrix, to_remove_indices)\n",
    "    \n",
    "    def delete_column_lil(mat: lil_matrix, *i) -> lil_matrix:\n",
    "        mat = mat.transpose()\n",
    "        mat = ViewMatrix.delete_row_lil(mat, *i)\n",
    "        return mat.transpose()\n",
    "    \n",
    "    def delete_row_lil(mat: lil_matrix, *i) -> lil_matrix:\n",
    "        if not isinstance(mat, lil_matrix):\n",
    "            raise ValueError(\"works only for LIL format -- use .tolil() first\")\n",
    "        mat = mat.copy()\n",
    "        mat.rows = np.delete(mat.rows, i)\n",
    "        mat.data = np.delete(mat.data, i)\n",
    "        mat._shape = (mat.rows.shape[0], mat._shape[1])\n",
    "        return mat\n",
    "    def to_csr(self):\n",
    "        train_data = self.view_matrix.astype(np.float64)\n",
    "        train_data = train_data.tocoo()\n",
    "        train_data.data = np.log10(train_data.data) + 1\n",
    "        train_data = train_data.tocsr()\n",
    "        return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALSReady(path: str, l = 2):\n",
    "    now = time.time()\n",
    "    matrix = ViewMatrix.load_matrix(path)\n",
    "    print('View matrix loaded in', time.time() - now, 'seconds.')\n",
    "\n",
    "    now = time.time()\n",
    "    sparce_matrix = matrix.to_csr()\n",
    "    matrix.make_dense(user_min_view = l, \n",
    "                      item_min_view = l)\n",
    "    implicit_matrix = matrix.to_csr()\n",
    "    print('matrix has been made dense in', time.time() - now, 'seconds.')\n",
    "    return matrix, sparce_matrix, implicit_matrix\n",
    "\n",
    "def CFTrain(matrix, implicit_matrix, _alpha = 15, _facs = 20, _itr = 15, save = False):\n",
    "    \n",
    "    now = time.time()\n",
    "    als_model = ALS.Als(num_factors = _facs,\n",
    "                        iterations = _itr,\n",
    "                        num_threads = 10,\n",
    "                        alpha = _alpha)\n",
    "\n",
    "    \n",
    "    als_model.fit(implicit_matrix)\n",
    "    alsTime = time.time() - now\n",
    "    print('ALS model is fitted in', alsTime, 'seconds.')\n",
    "    if save:\n",
    "        print('Saving Data ...')\n",
    "        matrix.item_indexer.dump('./chetor.com/alisResult/ALS/ali_item_indexer_factorized.indexer')\n",
    "        matrix.user_indexer.dump('./chetor.com/alisResult/ALS/ali_user_indexer_factorized.indexer')\n",
    "        np.save('./chetor.com/alisResult/ALS/ali_items_vectors.npy', als_model.item_vectors)\n",
    "        np.save('./chetor.com/alisResult/ALS/ali_users_vectors.npy', als_model.user_vectors)\n",
    "\n",
    "    return als_model.item_vectors, als_model.user_vectors, alsTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-aberdeen",
   "metadata": {},
   "source": [
    "implicit matrix ro migire va ye bakhshisho baramun test o train mikone ke ye bakhshi az cell ha sefr shodan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excess-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_set_precision_recall(implicit_matrix, _test_size = 0.05, test_cells = 0.2):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = _test_size)\n",
    "    print('test_shape', test.shape, 'train_shape (which we cant process bc of RAM)', train.shape)\n",
    "    rows,cols = test.nonzero()\n",
    "    delete_index = [(rows[i], cols[i]) for i in random.sample(range(1, len(rows)), int(len(rows)*test_cells))]\n",
    "    print(\"total cells\", len(rows), \"number of deleted cells\", len(delete_index))\n",
    "    \n",
    "    x_train = scipy.sparse.csr_matrix(test.shape)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if (i, j) in delete_index:\n",
    "            continue\n",
    "        x_train[i, j] = test[i, j]\n",
    "    return x_train, test, delete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k_old(test, test_approx, k = 10):\n",
    "    metric = []\n",
    "    metric2 = []\n",
    "    for i in tqdm(range(len(test))):\n",
    "        t = n_argmax(test[i], k)\n",
    "        nonz = np.nonzero(test[i])[0]\n",
    "        ta = n_argmax(test_approx[i], k)   \n",
    "        rec_rel = 0\n",
    "        for i in nonz:\n",
    "            if i in ta:\n",
    "                rec_rel += 1\n",
    "\n",
    "        metric.append(rec_rel/len(nonz))\n",
    "        metric2.append(rec_rel/k)\n",
    "    return np.mean(np.array(metric)), np.mean(np.array(metric2))\n",
    "\n",
    "def hit_rate_at_k(deleted, x_train, test_approx, k = 10):\n",
    "    found = []\n",
    "    for i in tqdm(range(len(test_approx))):\n",
    "        ta = list(n_argmax(test_approx[i], 30))\n",
    "        nonz = np.nonzero(x_train[i])[0]\n",
    "        same_old = []\n",
    "        for l in range(len(ta)):\n",
    "            if ta[l] in nonz:\n",
    "                same_old.append(l)\n",
    "\n",
    "        for l in same_old[::-1]:\n",
    "            ta.pop(l)\n",
    "        ta = ta[:k]        \n",
    "        for j in ta:\n",
    "            found.append((i, j))\n",
    "    same = 0\n",
    "    for i in tqdm(deleted):\n",
    "        if i in found:\n",
    "            same += 1\n",
    "    print(same, len(deleted), same/len(deleted))\n",
    "    return same/len(deleted)\n",
    "\n",
    "def visited_at_k(x_train, test_approx, k = 10):\n",
    "    same_old = []\n",
    "    for i in tqdm(range(len(test_approx))):\n",
    "        ta = list(n_argmax(test_approx[i], k))\n",
    "        nonz = np.nonzero(x_train[i])[0]\n",
    "        for l in range(len(ta)):\n",
    "            if ta[l] in nonz:\n",
    "                same_old.append(l)\n",
    "    rows,cols = x_train.nonzero()\n",
    "    return len(same_old)/len(rows)\n",
    "\n",
    "def n_argmax(a, n):\n",
    "    ranked = np.argsort(a)\n",
    "    largest_indices = ranked[::-1][:n]\n",
    "    return largest_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-module",
   "metadata": {},
   "source": [
    "### Ready for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chief-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View matrix loaded in 6.775495767593384 seconds.\n",
      "Number of users which should be deleted: 1863687\n",
      "Number products which should be deleted: 1308\n",
      "Number of users which should be deleted: 265\n",
      "Number products which should be deleted: 4\n",
      "Number of users which should be deleted: 1\n",
      "Number products which should be deleted: 1\n",
      "Number of users which should be deleted: 0\n",
      "Number products which should be deleted: 0\n",
      "matrix has been made dense in 17.475834846496582 seconds.\n"
     ]
    }
   ],
   "source": [
    "matrix, sparce_matrix, implicit_matrix = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dying-father",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233197, 6877)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virgin-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_matrix = implicit_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "periodic-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit_matrix = scipy.sparse.csr_matrix(implicit_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-luxembourg",
   "metadata": {},
   "source": [
    "### Running ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_vectors, user_vectors, alsTime = \\\n",
    "# CFTrain(None, train, _alpha = 10, _facs = 20, _itr = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-benchmark",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-edwards",
   "metadata": {},
   "source": [
    "precision@k, recall@k, hit_rate@k, visited_rate@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "loaded-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_shape (16324, 6877) train_shape (which we cant process bc of RAM) (216873, 6877)\n",
      "total cells 39169 number of deleted cells 7833\n"
     ]
    }
   ],
   "source": [
    "x_train, test, deleted = generate_test_set_precision_recall(implicit_matrix, _test_size = 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stretch-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16324, 6877) (16324, 6877) 7833 <class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, test.shape, len(deleted), type(test), type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sexual-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model is fitted in 1.5320508480072021 seconds.\n"
     ]
    }
   ],
   "source": [
    "item_vectors, user_vectors, alsTime = \\\n",
    "CFTrain(None, x_train, _alpha = 10, _facs = 20, _itr = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unable-nudist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6877, 20) (16324, 20)\n",
      "(16324, 6877) (16324, 6877)\n"
     ]
    }
   ],
   "source": [
    "print(item_vectors.shape, user_vectors.shape)\n",
    "test_approx = np.matmul(user_vectors, item_vectors.T)\n",
    "print(test_approx.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-jerusalem",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "hit_rate@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "familiar-winner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:07<00:00, 2160.77it/s]\n",
      "100%|██████████| 7833/7833 [21:34<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209 7833 0.28201200051066005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28201200051066005"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "concerned-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:07<00:00, 2148.24it/s]\n",
      "100%|██████████| 7833/7833 [11:21<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752 7833 0.22366909230180007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22366909230180007"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sized-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:07<00:00, 2242.78it/s]\n",
      "100%|██████████| 7833/7833 [06:25<00:00, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474 7833 0.1881782203498021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1881782203498021"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "tough-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:07<00:00, 2252.05it/s]\n",
      "100%|██████████| 7833/7833 [04:11<00:00, 31.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247 7833 0.1591982637559045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1591982637559045"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-turkish",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "visited@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "labeled-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:05<00:00, 2734.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4924049017104927"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_at_k(x_train.toarray(), test_approx, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "equipped-facing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:05<00:00, 2838.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4137094715343375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_at_k(x_train.toarray(), test_approx, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "known-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16324/16324 [00:05<00:00, 2903.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2935601225427623"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_at_k(x_train.toarray(), test_approx, k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-helena",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "Average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "criminal-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_AP(implicit_matrix, _test_size = 0.05):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = _test_size)\n",
    "    print('test_shape', test.shape, 'train_shape (which we cant process bc of RAM)', train.shape)\n",
    "    rows, cols = test.nonzero()\n",
    "    for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "charming-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_shape (11660, 6877) train_shape (which we cant process bc of RAM) (221537, 6877)\n",
      "[0 0 1 1 2 2 3 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "prepare_data_for_AP(implicit_matrix, _test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_set_precision_recall(implicit_matrix, _test_size = 0.05, test_cells = 0.2):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = _test_size)\n",
    "    print('test_shape', test.shape, 'train_shape (which we cant process bc of RAM)', train.shape)\n",
    "    rows, cols = test.nonzero()\n",
    "    delete_index = [(rows[i], cols[i]) for i in random.sample(range(1, len(rows)), int(len(rows)*test_cells))]\n",
    "    print(\"total cells\", len(rows), \"number of deleted cells\", len(delete_index))\n",
    "    \n",
    "    x_train = scipy.sparse.csr_matrix(test.shape)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if (i, j) in delete_index:\n",
    "            continue\n",
    "        x_train[i, j] = test[i, j]\n",
    "    return x_train, test, delete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-reflection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-parameter",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "MAE per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monthly-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View matrix loaded in 7.785526514053345 seconds.\n",
      "Number of users which should be deleted: 1863687\n",
      "Number products which should be deleted: 1308\n",
      "Number of users which should be deleted: 265\n",
      "Number products which should be deleted: 4\n",
      "Number of users which should be deleted: 1\n",
      "Number products which should be deleted: 1\n",
      "Number of users which should be deleted: 0\n",
      "Number products which should be deleted: 0\n",
      "matrix has been made dense in 20.18146324157715 seconds.\n"
     ]
    }
   ],
   "source": [
    "matrix, sparce_matrix, implicit_matrix = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coral-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(implicit_matrix, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affiliated-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58300, 6877)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "covered-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itr_MAE(test_set, itr):\n",
    "    item_vectors, user_vectors, alsTime = \\\n",
    "    CFTrain(None, test_set, _alpha = 10, _facs = 20, _itr = itr)\n",
    "    approximated_matrix = np.matmul(user_vectors, item_vectors.T)\n",
    "    absolute_error1 = np.absolute(test[:15000] - approximated_matrix[:15000])\n",
    "    absolute_error2 = np.absolute(test[15000:30000] - approximated_matrix[15000:30000])\n",
    "    absolute_error3 = np.absolute(test[30000:45000] - approximated_matrix[30000:45000])\n",
    "    absolute_error4 = np.absolute(test[45000:] - approximated_matrix[45000:])\n",
    "    return (np.mean(absolute_error1)+np.mean(absolute_error2)+np.mean(absolute_error3)+np.mean(absolute_error4))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model is fitted in 0.08308863639831543 seconds.\n"
     ]
    }
   ],
   "source": [
    "MAEs = []\n",
    "for i in range(5):\n",
    "    MAEs.append(itr_MAE(test, i))\n",
    "    print(MAEs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "great-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model is fitted in 0.3134288787841797 seconds.\n"
     ]
    }
   ],
   "source": [
    "item_vectors, user_vectors, alsTime = \\\n",
    "CFTrain(None, test, _alpha = 10, _facs = 20, _itr = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximated_matrix = np.matmul(user_vectors, item_vectors.T)\n",
    "absolute_error1 = np.absolute(test[:15000] - approximated_matrix[:15000])\n",
    "absolute_error2 = np.absolute(test[15000:30000] - approximated_matrix[15000:30000])\n",
    "absolute_error3 = np.absolute(test[30000:45000] - approximated_matrix[30000:45000])\n",
    "absolute_error4 = np.absolute(test[45000:] - approximated_matrix[45000:])\n",
    "(np.mean(absolute_error1)+np.mean(absolute_error2)+np.mean(absolute_error3)+np.mean(absolute_error4))/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-audio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
