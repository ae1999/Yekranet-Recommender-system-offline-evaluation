{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timeit\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ./indexer\n",
    "from indexer import AppendIndexer\n",
    "import ALS\n",
    "\n",
    "# Annoy\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "#SKLearn \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse import lil_matrix\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewMatrix:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.original = True\n",
    "        self.item_indexer = AppendIndexer.load('./chetor.com/view_matrix/item_indexer.indexer')\n",
    "        self.user_indexer = AppendIndexer.load('./chetor.com/view_matrix/user_indexer.indexer')\n",
    "        \n",
    "    def load_matrix(path):\n",
    "        \n",
    "        matrix = ViewMatrix(path)\n",
    "\n",
    "        try:\n",
    "            matrix.view_matrix = ViewMatrix \\\n",
    "                .load_sparse_lil(path)\n",
    "        except:\n",
    "            print('Error: loading', path)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def load_sparse_lil(filename):\n",
    "        loader = np.load(filename, allow_pickle=True)\n",
    "        result = lil_matrix(tuple(loader[\"shape\"]), dtype=str(loader[\"dtype\"]))\n",
    "        result.data = loader[\"data\"]\n",
    "        result.rows = loader[\"rows\"]\n",
    "        return result\n",
    "    \n",
    "    def make_dense(self, user_min_view, item_min_view):\n",
    "        self.original = False\n",
    "        while True:\n",
    "            removed_rows_cnt = self.trim_users_with_few_views(user_min_view)\n",
    "            removed_columns_cnt = self.trim_columns_with_few_views(item_min_view)\n",
    "            if not removed_columns_cnt and not removed_rows_cnt:\n",
    "                break\n",
    "\n",
    "    def trim_users_with_few_views(self, user_min_view):\n",
    "        removing_row_indices = list(np.where(self.view_matrix.getnnz(1) < user_min_view)[0])\n",
    "        print('Number of users which should be deleted:', len(removing_row_indices))\n",
    "        self.trim_user_indices(to_remove_indices=removing_row_indices)\n",
    "        return len(removing_row_indices)\n",
    "\n",
    "    def trim_columns_with_few_views(self, column_min_view):\n",
    "        removing_column_indices = list(np.where(self.view_matrix.getnnz(0) < column_min_view)[0])\n",
    "        print('Number products which should be deleted:', len(removing_column_indices))\n",
    "        self.trim_column_indices(to_remove_indices=removing_column_indices)\n",
    "        return len(removing_column_indices)\n",
    "    \n",
    "    def trim_user_indices(self, to_remove_indices):\n",
    "        self.user_indexer.remove_indexes(to_remove_indices)\n",
    "        self.view_matrix = ViewMatrix.delete_row_lil(self.view_matrix, to_remove_indices)\n",
    "    \n",
    "    def trim_column_indices(self, to_remove_indices):\n",
    "        self.item_indexer.remove_indexes(to_remove_indices)\n",
    "        self.view_matrix = ViewMatrix.delete_column_lil(self.view_matrix, to_remove_indices)\n",
    "    \n",
    "    def delete_column_lil(mat: lil_matrix, *i) -> lil_matrix:\n",
    "        mat = mat.transpose()\n",
    "        mat = ViewMatrix.delete_row_lil(mat, *i)\n",
    "        return mat.transpose()\n",
    "    \n",
    "    def delete_row_lil(mat: lil_matrix, *i) -> lil_matrix:\n",
    "        if not isinstance(mat, lil_matrix):\n",
    "            raise ValueError(\"works only for LIL format -- use .tolil() first\")\n",
    "        mat = mat.copy()\n",
    "        mat.rows = np.delete(mat.rows, i)\n",
    "        mat.data = np.delete(mat.data, i)\n",
    "        mat._shape = (mat.rows.shape[0], mat._shape[1])\n",
    "        return mat\n",
    "    def to_csr(self):\n",
    "        train_data = self.view_matrix.astype(np.float64)\n",
    "        train_data = train_data.tocoo()\n",
    "        train_data.data = np.log10(train_data.data) + 1\n",
    "        train_data = train_data.tocsr()\n",
    "        return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALSReady(path: str, l = 2):\n",
    "    now = time.time()\n",
    "    matrix = ViewMatrix.load_matrix(path)\n",
    "    print('View matrix loaded in', time.time() - now, 'seconds.')\n",
    "\n",
    "    now = time.time()\n",
    "    sparce_matrix = matrix.to_csr()\n",
    "    matrix.make_dense(user_min_view = l, \n",
    "                      item_min_view = l)\n",
    "    implicit_matrix = matrix.to_csr()\n",
    "    print('matrix has been made dense in', time.time() - now, 'seconds.')\n",
    "    return matrix, sparce_matrix, implicit_matrix\n",
    "\n",
    "def CFTrain(matrix, implicit_matrix, _alpha = 15, _facs = 20, _itr = 15, save = False):\n",
    "    \n",
    "    now = time.time()\n",
    "    als_model = ALS.Als(num_factors = _facs,\n",
    "                        iterations = _itr,\n",
    "                        num_threads = 10,\n",
    "                        alpha = _alpha)\n",
    "\n",
    "    \n",
    "    als_model.fit(implicit_matrix)\n",
    "    alsTime = time.time() - now\n",
    "    print('ALS model is fitted in', alsTime, 'seconds.')\n",
    "    if save:\n",
    "        print('Saving Data ...')\n",
    "        matrix.item_indexer.dump('./chetor.com/alisResult/ALS/ali_item_indexer_factorized.indexer')\n",
    "        matrix.user_indexer.dump('./chetor.com/alisResult/ALS/ali_user_indexer_factorized.indexer')\n",
    "        np.save('./chetor.com/alisResult/ALS/ali_items_vectors.npy', als_model.item_vectors)\n",
    "        np.save('./chetor.com/alisResult/ALS/ali_users_vectors.npy', als_model.user_vectors)\n",
    "\n",
    "    return als_model.item_vectors, als_model.user_vectors, alsTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-aberdeen",
   "metadata": {},
   "source": [
    "implicit matrix ro migire va ye bakhshisho baramun test o train mikone ke ye bakhshi az cell ha sefr shodan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excess-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_set_precision_recall(implicit_matrix, _test_size = 0.05, test_cells = 0.2):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = _test_size)\n",
    "    print('test_shape', test.shape, 'train_shape (which we cant process bc of RAM)', train.shape)\n",
    "    rows,cols = test.nonzero()\n",
    "    delete_index = [(rows[i], cols[i]) for i in random.sample(range(1, len(rows)), int(len(rows)*test_cells))]\n",
    "    print(\"total cells\", len(rows), \"number of deleted cells\", len(delete_index))\n",
    "    \n",
    "    x_train = scipy.sparse.csr_matrix(test.shape)\n",
    "    for i, j in tqdm(zip(rows, cols)):\n",
    "        if (i, j) in delete_index:\n",
    "            continue\n",
    "        x_train[i, j] = test[i, j]\n",
    "    return x_train, test, delete_index\n",
    "\n",
    "def prepare_data_for_AP(implicit_matrix, _test_size = 0.05):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = _test_size)\n",
    "    print('test_shape', test.shape, 'train_shape (which we cant process bc of RAM)', train.shape)\n",
    "    rows, cols = test.nonzero()\n",
    "    unique, counts = np.unique(rows, return_counts=True)\n",
    "    commulative_count = [0]\n",
    "    for i in counts:\n",
    "        commulative_count.append(commulative_count[-1] + i)\n",
    "    delete_row = []\n",
    "    for i in range(1, len(commulative_count)):\n",
    "        delete_row.append(np.random.randint(commulative_count[i-1], commulative_count[i]))\n",
    "    delete_index = [(rows[i], cols[i]) for i in delete_row]\n",
    "    # print(delete_row[:10], delete_index[:10], rows[:10], cols[:10], random.randrange(commulative_count[0], 10, 2) )\n",
    "    print(\"total cells\", len(rows), \"number of deleted cells\", len(delete_index))\n",
    "    \n",
    "    x_train = scipy.sparse.csr_matrix(test.shape)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if (i, j) in delete_index:\n",
    "            continue\n",
    "        x_train[i, j] = test[i, j]\n",
    "    return x_train, test, delete_index\n",
    "\n",
    "def prepare_data_for_MAE(implicit_matrix, set_size = 0.05):\n",
    "    train, test = train_test_split(implicit_matrix, shuffle=False, test_size = set_size)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate_at_k(deleted, x_train, test_approx, k = 10):\n",
    "    found = []\n",
    "    for i in tqdm(range(len(test_approx))):\n",
    "        ta = list(n_argmax(test_approx[i], 30))\n",
    "        nonz = np.nonzero(x_train[i])[0]\n",
    "        same_old = []\n",
    "        for l in range(len(ta)):\n",
    "            if ta[l] in nonz:\n",
    "                same_old.append(l)\n",
    "\n",
    "        for l in same_old[::-1]:\n",
    "            ta.pop(l)\n",
    "        ta = ta[:k]        \n",
    "        for j in ta:\n",
    "            found.append((i, j))\n",
    "    same = 0\n",
    "    for i in tqdm(deleted):\n",
    "        if i in found:\n",
    "            same += 1\n",
    "    print(same, len(deleted), same/len(deleted))\n",
    "    return same/len(deleted)\n",
    "\n",
    "def visited_at_k(x_train, test_approx, k = 10):\n",
    "    same_old = []\n",
    "    for i in tqdm(range(len(test_approx))):\n",
    "        ta = list(n_argmax(test_approx[i], k))\n",
    "        nonz = np.nonzero(x_train[i])[0]\n",
    "        for l in range(len(ta)):\n",
    "            if ta[l] in nonz:\n",
    "                same_old.append(l)\n",
    "    rows,cols = x_train.nonzero()\n",
    "    return len(same_old)/len(rows)\n",
    "\n",
    "def n_argmax(a, n):\n",
    "    ranked = np.argsort(a)\n",
    "    largest_indices = ranked[::-1][:n]\n",
    "    return largest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subsequent-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random search\n",
    "itrs = [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
    "alphas = [5, 5, 5, 5, 10, 10, 10, 10, 50, 50, 50, 50, 100, 100, 100, 100]\n",
    "factors = [5, 10, 20, 40, 5, 10, 20, 40, 5, 10, 20, 40, 5, 10, 20, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-benchmark",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-edwards",
   "metadata": {},
   "source": [
    "accuracy metrics:\n",
    "- recall@k, hit_rate@k\n",
    "- visited_rate@k\n",
    "- MAE on train set per iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-occasions",
   "metadata": {},
   "source": [
    "time metrics:\n",
    "- training time\n",
    "- query time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-jerusalem",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "hit_rate@k, visited@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chief-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, sparce_matrix, implicit_matrix = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=2)\n",
    "# print(implicit_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brazilian-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to test\n",
    "# x_train, test, deleted = generate_test_set_precision_recall(implicit_matrix, _test_size = 0.07)\n",
    "# print('train set shape:', x_train.shape, '\\ntest set shape:', test.shape, '\\ndeleted cells:', len(deleted), type(test), type(x_train))\n",
    "# #training ALS model\n",
    "# item_vectors, user_vectors, alsTime = \\\n",
    "# CFTrain(None, x_train, _alpha = 10, _facs = 20, _itr = 20)\n",
    "# print(item_vectors.shape, user_vectors.shape)\n",
    "# test_approx = np.matmul(user_vectors, item_vectors.T)\n",
    "# print(test_approx.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "linear-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 6)\n",
    "# hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "labeled-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visited_at_k(x_train.toarray(), test_approx, k = 6)\n",
    "# visited_at_k(x_train.toarray(), test_approx, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caring-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_visited_hitRate(alphas, itrs, factors, _l = 3, data_set_size = 0.072):\n",
    "    visited3s = []\n",
    "    hitRate3s = []\n",
    "    visited6s = []\n",
    "    hitRate6s = []\n",
    "    AP3s = []\n",
    "    AP6s = []\n",
    "    trainingTime = []\n",
    "    matrix, sparce_matrix, implicit_matrix = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=_l)\n",
    "    x_train, test, deleted = generate_test_set_precision_recall(implicit_matrix, _test_size = data_set_size)\n",
    "    for a,i,f in zip(alphas, itrs, factors):\n",
    "        item_vectors, user_vectors, alsTime = \\\n",
    "        CFTrain(None, x_train, _alpha = a, _facs = f, _itr = i)\n",
    "        trainingTime.append(alsTime)\n",
    "        test_approx = np.matmul(user_vectors, item_vectors.T)\n",
    "        visited3s.append(visited_at_k(x_train.toarray(), test_approx, k = 3))\n",
    "        print(visited3s)\n",
    "        visited6s.append(visited_at_k(x_train.toarray(), test_approx, k = 6))\n",
    "        print(visited6s)\n",
    "        hitRate3s.append(hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 3))\n",
    "        print(hitRate3s)\n",
    "        hitRate6s.append(hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 6))\n",
    "        print(hitRate6s)\n",
    "        AP3s.append(hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 3))\n",
    "        print(hitRate6s)\n",
    "        AP6s.append(hit_rate_at_k(deleted, x_train.toarray(), test_approx, k = 6))\n",
    "        print(hitRate6s)\n",
    "    return visited3s, visited6s, hitRate3s, hitRate6s, AP3s, AP6s, trainingTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-helena",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "Average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decent-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, sparce_matrix, implicit_matrix_AP = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charming-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing\n",
    "# x_train_AP, test_AP, delete_index_AP = prepare_data_for_AP(implicit_matrix_AP, _test_size = 0.2)\n",
    "# #training ALS model\n",
    "# item_vectors_AP, user_vectors_AP, alsTime_AP = \\\n",
    "# CFTrain(None, x_train_AP, _alpha = 10, _facs = 20, _itr = 20)\n",
    "# print(item_vectors_AP.shape, user_vectors_AP.shape)\n",
    "# test_approx_AP = np.matmul(user_vectors_AP, item_vectors_AP.T)\n",
    "# print(test_approx_AP.shape, test_AP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diverse-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"average precision k = 3\", hit_rate_at_k(delete_index_AP, x_train_AP, test_approx_AP, k = 3))\n",
    "# print(\"average precision k = 6\", hit_rate_at_k(delete_index_AP, x_train_AP, test_approx_AP, k = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "running-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_AP(alphas, itrs, factors, _l = 3, data_set_size = 0.2):\n",
    "    AP3s = []\n",
    "    AP6s = []\n",
    "    time\n",
    "    matrix, sparce_matrix, implicit_matrix_AP = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=_l)\n",
    "    x_train_AP, test_AP, delete_index_AP = prepare_data_for_AP(implicit_matrix_AP, _test_size = data_set_size)\n",
    "    for a,i,f in zip(alphas, itrs, factors):\n",
    "        item_vectors_AP, user_vectors_AP, alsTime_AP = \\\n",
    "        CFTrain(None, x_train_AP, _alpha = a, _facs = f, _itr = i)\n",
    "        test_approx_AP = np.matmul(user_vectors_AP, item_vectors_AP.T)\n",
    "        AP3s.append(hit_rate_at_k(delete_index_AP, x_train_AP, test_approx_AP, k = 3))\n",
    "        AP6s.append(hit_rate_at_k(delete_index_AP, x_train_AP, test_approx_AP, k = 6))\n",
    "    return AP3s, AP6s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-parameter",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------\n",
    "MAE per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monthly-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, sparce_matrix, implicit_matrix = ALSReady('./chetor.com/view_matrix/lil_matrix.npz', l=2)\n",
    "# train = prepare_data_for_MAE(implicit_matrix, set_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coral-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE_calc(train, itr = 10, facs = 20):\n",
    "    item_vectors, user_vectors, alsTime = \\\n",
    "    CFTrain(None, train, _alpha = 10, _facs = 20, _itr = itr)\n",
    "    approximated_matrix = np.matmul(user_vectors, item_vectors.T)\n",
    "    absolute_error = np.absolute(train - approximated_matrix)\n",
    "    return np.mean(absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "registered-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEs = []\n",
    "# for i in [2,5,7,10,15,20,30,40,80,100]:\n",
    "#     MAEs.append(MAE_calc(train, itr = i))\n",
    "#     print(MAEs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "oriented-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(19), MAEs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-factor",
   "metadata": {},
   "source": [
    "## Run on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "exotic-bunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View matrix loaded in 6.447596073150635 seconds.\n",
      "Number of users which should be deleted: 1863687\n",
      "Number products which should be deleted: 1308\n",
      "Number of users which should be deleted: 265\n",
      "Number products which should be deleted: 4\n",
      "Number of users which should be deleted: 1\n",
      "Number products which should be deleted: 1\n",
      "Number of users which should be deleted: 0\n",
      "Number products which should be deleted: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/yektanet/.local/lib/python3.8/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n",
      "90it [00:00, 898.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix has been made dense in 16.66092562675476 seconds.\n",
      "test_shape (16791, 6877) train_shape (which we cant process bc of RAM) (216406, 6877)\n",
      "total cells 40230 number of deleted cells 8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40230it [00:36, 1087.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model is fitted in 0.4699232578277588 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16791/16791 [00:05<00:00, 2800.89it/s]\n",
      "  2%|▏         | 272/16791 [00:00<00:06, 2710.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14190280884911757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16791/16791 [00:06<00:00, 2572.54it/s]\n",
      "  1%|          | 209/16791 [00:00<00:07, 2087.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18791946308724833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16791/16791 [00:08<00:00, 2075.40it/s]\n",
      "100%|██████████| 8046/8046 [10:53<00:00, 12.32it/s]\n",
      "  0%|          | 0/16791 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845 8046 0.10502112851106139\n",
      "[0.10502112851106139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16791/16791 [00:10<00:00, 1667.40it/s]\n",
      "100%|██████████| 8046/8046 [24:11<00:00,  5.54it/s]\n",
      "  1%|          | 118/16791 [00:00<00:14, 1177.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119 8046 0.13907531692766592\n",
      "[0.13907531692766592]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 6210/16791 [00:04<00:08, 1316.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2ef75ab7752b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisited3s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited6s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhitRate3s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhitRate6s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_visited_hitRate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-8129b971d6bf>\u001b[0m in \u001b[0;36mcalc_visited_hitRate\u001b[0;34m(alphas, itrs, factors, _l, data_set_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mhitRate6s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit_rate_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhitRate6s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mAP3s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit_rate_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhitRate6s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mAP6s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhit_rate_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-591cccae2e5d>\u001b[0m in \u001b[0;36mhit_rate_at_k\u001b[0;34m(deleted, x_train, test_approx, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_approx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_approx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnonz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msame_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-591cccae2e5d>\u001b[0m in \u001b[0;36mn_argmax\u001b[0;34m(a, n)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mranked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mlargest_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlargest_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \"\"\"\n\u001b[0;32m-> 1112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visited3s, visited6s, hitRate3s, hitRate6s = calc_visited_hitRate(alphas, itrs, factors, _l = 2, data_set_size = 0.072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
